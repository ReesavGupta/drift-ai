{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a2b6b3",
   "metadata": {},
   "source": [
    "### What this notebook is doing (in simple words)\n",
    "\n",
    "This notebook builds a **productivity prediction model** for employees using their working hours, number of tasks, and absences.\n",
    "In simple terms, here is what happens:\n",
    "\n",
    "1. **Load and inspect the data**  \n",
    "   We load the CSV file and check the columns, data types, missing values, and duplicates.  \n",
    "   The key columns are: `login_time`, `logout_time`, `total_tasks_completed`, `weekly_absences`, and the target `productivity_score`.\n",
    "\n",
    "2. **Train simple baseline models**  \n",
    "   First, we try basic models (like SGDRegressor and Ridge) on the original features after scaling.  \n",
    "   The metrics (MSE, RMSE, MAE, R²) show that these simple models do not explain much of the variance in productivity (R² is around 0.0–0.03).\n",
    "\n",
    "3. **Create smarter features about how people work**  \n",
    "   We manually engineer new features, such as:  \n",
    "   - `daily_work_hours` = logout_time − login_time  \n",
    "   - `tasks_per_hour` = total_tasks_completed / daily_work_hours  \n",
    "   - `absenteeism_rate` = weekly_absences / 5  \n",
    "   These features try to capture *how* someone works (efficiency and presence), not just raw counts.\n",
    "\n",
    "4. **Build a clean ML pipeline with feature engineering + scaling + model**  \n",
    "   We wrap the feature creation, scaling, and the regression model into a single `Pipeline`.  \n",
    "   This makes the workflow easier to maintain and avoids mistakes (for example, forgetting to apply the same transforms to train and test).\n",
    "\n",
    "5. **Evaluate and compare the final models**  \n",
    "   We compare the errors (MSE, RMSE, MAE) and R² scores before and after feature engineering.  \n",
    "   Even though the overall R² is still modest, the engineered features give a more meaningful view of productivity and can be used in an API to score new employees in a consistent way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd6f125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903cc393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>login_time</th>\n",
       "      <th>logout_time</th>\n",
       "      <th>total_tasks_completed</th>\n",
       "      <th>weekly_absences</th>\n",
       "      <th>productivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>222</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     employee_id  login_time  logout_time  total_tasks_completed  \\\n",
       "21            22           8           18                     73   \n",
       "93            94           8           20                     32   \n",
       "118          119           8           18                    105   \n",
       "221          222           8           18                    113   \n",
       "127          128           9           18                    119   \n",
       "\n",
       "     weekly_absences  productivity_score  \n",
       "21                 0                  78  \n",
       "93                 4                  87  \n",
       "118                4                  94  \n",
       "221                1                  63  \n",
       "127                2                  88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../csv/data.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd83aa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype\n",
      "---  ------                 --------------  -----\n",
      " 0   employee_id            300 non-null    int64\n",
      " 1   login_time             300 non-null    int64\n",
      " 2   logout_time            300 non-null    int64\n",
      " 3   total_tasks_completed  300 non-null    int64\n",
      " 4   weekly_absences        300 non-null    int64\n",
      " 5   productivity_score     300 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 14.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40c666",
   "metadata": {},
   "source": [
    "### Checking the raw data\n",
    "\n",
    "In the first few cells, I:\n",
    "\n",
    "- Load the dataset from the CSV file.\n",
    "- Look at a random sample of rows to get a feel for the numbers.\n",
    "- Use `df.info()`, `isna().sum()`, and `duplicated().sum()` to confirm there are no missing values or duplicate rows.\n",
    "\n",
    "After that, I drop the `employee_id` column because it is just an identifier and does not help the model learn patterns about productivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23ef16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id              0\n",
       "login_time               0\n",
       "logout_time              0\n",
       "total_tasks_completed    0\n",
       "weekly_absences          0\n",
       "productivity_score       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87799368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f804753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['employee_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d93ff",
   "metadata": {},
   "source": [
    "### First baseline models (before feature engineering)\n",
    "\n",
    "Here I build a very simple setup:\n",
    "\n",
    "- I split the data into **train** and **test** sets.\n",
    "- I scale the numeric features using `StandardScaler`.\n",
    "- I train two models:\n",
    "  - `SGDRegressor` (a linear model trained with gradient descent).\n",
    "  - `Ridge` (a regularized linear regression).\n",
    "\n",
    "The evaluation metrics (MSE, RMSE, MAE, R²) show that these baseline models only explain a very small part of the variation in `productivity_score` (R² is close to 0). This tells me that just feeding the raw columns is not enough — I need better features that describe work behaviour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6f6cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor, Ridge\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.drop(columns=['productivity_score'])\n",
    "y = df['productivity_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6328d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e03c47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd_regressor', SGDRegressor(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "ridge_pipe = Pipeline(steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge_regressor', Ridge(alpha=1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6e23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_scaled, y_train)\n",
    "y_pred = pipe.predict(X_test_scaled)\n",
    "\n",
    "ridge_pipe.fit(X_train_scaled, y_train)\n",
    "y_ridge_pred = ridge_pipe.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7daf3cf",
   "metadata": {},
   "source": [
    "### Re-splitting and preparing for feature engineering\n",
    "\n",
    "Before building more advanced models, I:\n",
    "\n",
    "- Re-create `X` (inputs) and `y` (target), where `y` is `productivity_score`.\n",
    "- Do a fresh `train_test_split` so that I clearly separate the data used to train and test the new feature-engineered models.\n",
    "\n",
    "This keeps the workflow clean and makes it clear which data is used in the next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0244670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 286.84\n",
      "Root Mean Squared Error: 16.94\n",
      "Mean Absolute Error: 14.19\n",
      "R^2 Score: 0.03\n",
      "\n",
      "Ridge Regression Results:\n",
      "Mean Squared Error: 287.23\n",
      "Root Mean Squared Error: 16.95\n",
      "Mean Absolute Error: 14.20\n",
      "R^2 Score: 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\nRidge Regression Results:\")\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_ridge_pred)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test, y_ridge_pred)\n",
    "r2_ridge = r2_score(y_test, y_ridge_pred)\n",
    "print(f\"Mean Squared Error: {mse_ridge:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_ridge:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_ridge:.2f}\")\n",
    "print(f\"R^2 Score: {r2_ridge:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fbc0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb645e",
   "metadata": {},
   "source": [
    "### Creating better features about productivity\n",
    "\n",
    "In this step I define a custom transformer called `FeatureCreator`.\n",
    "It builds new features that are more meaningful for productivity:\n",
    "\n",
    "- **daily_work_hours** = logout_time − login_time (minimum of 1 hour to avoid division by zero).  \n",
    "  This approximates how long an employee actually worked.\n",
    "- **tasks_per_hour** = total_tasks_completed / daily_work_hours.  \n",
    "  This is a simple measure of efficiency: more tasks per hour usually means higher productivity.\n",
    "- **absenteeism_rate** = weekly_absences / 5.0.  \n",
    "  This captures how often someone is absent during a standard 5‑day work week.\n",
    "\n",
    "By returning these engineered features (plus the original task and absence counts), we give the model richer information that should help it understand who is productive and who is not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3cc6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['productivity_score'])\n",
    "y = df['productivity_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79973ac",
   "metadata": {},
   "source": [
    "### Building pipelines with feature engineering + models\n",
    "\n",
    "Now I combine everything into Scikit-Learn `Pipeline` objects:\n",
    "\n",
    "- One pipeline starts with `FeatureCreator`, then scales the engineered features, then fits an `SGDRegressor`.\n",
    "- Another pipeline scales the raw features and fits a regularized linear model (also using `SGDRegressor` with `alpha=0.1`).\n",
    "\n",
    "Wrapping steps into a pipeline ensures that:\n",
    "\n",
    "- The same transformations are always applied in the same order.\n",
    "- It is easy to reuse the trained pipeline later (for example, saving it and using it inside an API).\n",
    "- There is less risk of accidentally leaking information from the test set into the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e9cb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login_time</th>\n",
       "      <th>logout_time</th>\n",
       "      <th>total_tasks_completed</th>\n",
       "      <th>weekly_absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     login_time  logout_time  total_tasks_completed  weekly_absences\n",
       "232           8           21                     47                0\n",
       "59            8           19                     54                3\n",
       "6             8           21                     57                3\n",
       "185           8           18                     87                3\n",
       "173           8           21                     88                3\n",
       "..          ...          ...                    ...              ...\n",
       "188           8           21                     34                1\n",
       "71            9           19                    118                0\n",
       "106           8           19                     58                1\n",
       "270           9           17                     47                1\n",
       "102           9           17                     74                4\n",
       "\n",
       "[240 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e4544",
   "metadata": {},
   "source": [
    "### Evaluating the final models and saving for deployment\n",
    "\n",
    "In the final step I:\n",
    "\n",
    "- Evaluate the models using **MSE**, **RMSE**, **MAE**, and **R²** to see how well they predict `productivity_score`.\n",
    "- Even though the R² values are still low, the models now use more meaningful features (like work hours, tasks per hour, and absenteeism), which can be helpful for monitoring and ranking employees.\n",
    "- Save the final pipeline with `joblib.dump`, so it can be loaded later by the FastAPI service to make predictions on new employees.\n",
    "\n",
    "The key idea is that the model is now built in a structured, repeatable way and is ready to be used in a real application, even if the predictive power is modest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f45ffd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        X_transformed['daily_work_hours'] = X_transformed['logout_time'] - X_transformed['login_time']\n",
    "        X_transformed['daily_work_hours'] = np.maximum(X_transformed['daily_work_hours'], 1) \n",
    "        \n",
    "        X_transformed['tasks_per_hour'] = X_transformed['total_tasks_completed'] / X_transformed['daily_work_hours']\n",
    "        \n",
    "        X_transformed['absenteeism_rate'] = X_transformed['weekly_absences'] / 5.0 \n",
    "        \n",
    "        return X_transformed[['daily_work_hours', 'tasks_per_hour', 'absenteeism_rate', 'total_tasks_completed', 'weekly_absences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a90c23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    (\"feature_eng\", FeatureCreator()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sgd_regressor', SGDRegressor(max_iter=1000, tol=1e-3))])\n",
    "\n",
    "# regulaized linear model\n",
    "ridge_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SGDRegressor(alpha=0.1, max_iter=1000, tol=1e-3))           \n",
    "])\n",
    "\n",
    "\n",
    "ridge_mopel = ridge_pipeline.fit(X_train, y_train)\n",
    "y_ridge_final_pred = ridge_mopel.predict(X_test)\n",
    "\n",
    "\n",
    "sgd_model = pipe.fit(X_train, y_train)\n",
    "y_sgd_final_pred = sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81742ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 287.97\n",
      "Root Mean Squared Error: 16.97\n",
      "Mean Absolute Error: 14.25\n",
      "R^2 Score: 0.03\n",
      "SGDRegressor with Feature Engineering, Scaling, and PCA\n",
      "Mean Squared Error: 296.79\n",
      "Root Mean Squared Error: 17.23\n",
      "Mean Absolute Error: 14.68\n",
      "R^2 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_ridge_final_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_ridge_final_pred)\n",
    "r2 = r2_score(y_test, y_ridge_final_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "\n",
    "print(\"SGDRegressor with Feature Engineering, Scaling, and PCA\")\n",
    "mse = mean_squared_error(y_test, y_sgd_final_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_sgd_final_pred)\n",
    "r2 = r2_score(y_test, y_sgd_final_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e197ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_model.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(ridge_mopel, \"_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09091f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
